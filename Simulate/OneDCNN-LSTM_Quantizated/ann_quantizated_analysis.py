import torch
import torch.nn as nn
import torch.quantization as quantization
from torch.quantization import QuantStub, DeQuantStub
import numpy as np
import json
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import (accuracy_score, precision_score, recall_score,
                             f1_score, roc_auc_score, confusion_matrix,
                             classification_report, roc_curve, precision_recall_curve)
from torch.utils.data import Dataset, DataLoader
import time
import os
import warnings

warnings.filterwarnings('ignore')

# ä»é‡åŒ–æ¨¡å—å¯¼å…¥æ¨¡å‹ç±»ï¼Œç¡®ä¿ä¸€è‡´çš„é‡åŒ–è¡Œä¸º
try:
    from ann_quantization import HybridPrecision1DCLSTM
    print("ä»ann_quantization.pyå¯¼å…¥HybridPrecision1DCLSTMæ¨¡å‹ç±»")
except ImportError:
    print("è­¦å‘Š: æ— æ³•ä»ann_quantizationå¯¼å…¥æ¨¡å‹ç±»ï¼Œä½¿ç”¨æœ¬åœ°å®šä¹‰")
    # ä¿ç•™åŸæœ‰çš„æœ¬åœ°ç±»å®šä¹‰


class HybridPrecision1DCLSTM(nn.Module):
    """
    æ··åˆç²¾åº¦1DCNN-LSTMæ¨¡å‹
    CNNéƒ¨åˆ†ï¼šINT8é‡åŒ–
    LSTMéƒ¨åˆ†ï¼šFP32ä¿ç•™
    """

    def __init__(self, input_dim=1, seq_length=10, conv_channels=16,
                 lstm_hidden=32, lstm_layers=2, dropout_rate=0.2):
        super(HybridPrecision1DCLSTM, self).__init__()

        # é‡åŒ–è¾¹ç•Œæ ‡è®°
        self.quant = QuantStub()  # é‡åŒ–è¾“å…¥
        self.dequant = DeQuantStub()  # åé‡åŒ–è¾“å‡º

        # CNNéƒ¨åˆ†ï¼ˆå°†è¢«é‡åŒ–åˆ°INT8ï¼‰
        self.conv1d = nn.Conv1d(input_dim, conv_channels, kernel_size=3, padding=1)
        self.batchnorm = nn.BatchNorm1d(conv_channels)
        self.pool = nn.MaxPool1d(kernel_size=2, stride=2)

        # LSTMéƒ¨åˆ†ï¼ˆä¿æŒFP32ï¼‰
        self.lstm = nn.LSTM(
            input_size=conv_channels,
            hidden_size=lstm_hidden,
            num_layers=lstm_layers,
            batch_first=True,
            dropout=dropout_rate if lstm_layers > 1 else 0
        )

        self.dropout = nn.Dropout(dropout_rate)

        # è¾“å‡ºå±‚ï¼ˆFP32ï¼‰
        self.fc = nn.Linear(lstm_hidden, 1)

        # é‡åŒ–é…ç½®
        self.quant_config = {
            'qconfig': quantization.get_default_qconfig('fbgemm'),
            'dtype': torch.qint8
        }

    def forward(self, x):
        # é‡åŒ–è¾¹ç•Œï¼šå¼€å§‹é‡åŒ–
        x = self.quant(x)

        # è½¬æ¢ç»´åº¦
        x = x.transpose(1, 2)

        # CNNéƒ¨åˆ†ï¼ˆINT8é‡åŒ–åŒºåŸŸï¼‰
        x = self.conv1d(x)
        x = torch.relu(x)
        x = self.batchnorm(x)
        x = self.pool(x)

        # é‡åŒ–è¾¹ç•Œï¼šCNNè¾“å‡ºåé‡åŒ–
        x = self.dequant(x)

        # è½¬æ¢ç»´åº¦
        x = x.transpose(1, 2)

        # LSTMéƒ¨åˆ†ï¼ˆFP32ä¿ç•™åŒºåŸŸï¼‰
        lstm_out, _ = self.lstm(x)
        x = lstm_out[:, -1, :]
        x = self.dropout(x)

        # è¾“å‡ºå±‚
        x = self.fc(x)
        x = torch.sigmoid(x)

        return x

    def fuse_modules(self):
        """èåˆCNNéƒ¨åˆ†çš„æ¨¡å—ä»¥ä¼˜åŒ–é‡åŒ–æ€§èƒ½"""
        # èåˆå·ç§¯å±‚å’Œæ‰¹å½’ä¸€åŒ–å±‚
        torch.quantization.fuse_modules(self, [['conv1d', 'batchnorm']], inplace=True)

    def prepare_for_quantization(self):
        """å‡†å¤‡æ¨¡å‹è¿›è¡Œé‡åŒ–"""
        # è®¾ç½®é‡åŒ–é…ç½®
        self.qconfig = self.quant_config['qconfig']
        
        # ç¡®ä¿LSTMå’Œå…¨è¿æ¥å±‚ä¿æŒFP32ï¼ˆä¸é‡åŒ–ï¼‰
        self.lstm.qconfig = None
        self.fc.qconfig = None

        # å‡†å¤‡é‡åŒ–
        quantization.prepare(self, inplace=True)

    def convert_to_quantized(self):
        """è½¬æ¢ä¸ºé‡åŒ–æ¨¡å‹"""
        return quantization.convert(self, inplace=False)


class InferenceDataset(Dataset):
    """æ¨ç†æµ‹è¯•æ•°æ®é›†ç±»"""

    def __init__(self, data_file, sequence_length=10, generator_id=1, normalize=True):
        """
        åˆå§‹åŒ–æ¨ç†æ•°æ®é›†

        Args:
            data_file: JSONæ•°æ®æ–‡ä»¶è·¯å¾„ï¼ˆåŸå§‹æ•°æ®ç”Ÿæˆå™¨æ ¼å¼ï¼‰
            sequence_length: åºåˆ—é•¿åº¦ï¼ˆéœ€ä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰
            generator_id: å‘ç”Ÿå™¨ID (1-5)ï¼Œé»˜è®¤ä½¿ç”¨ç¬¬ä¸€ä¸ªå‘ç”Ÿå™¨
            normalize: æ˜¯å¦è¿›è¡Œæ ‡å‡†åŒ–ï¼ˆéœ€ä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰
        """
        self.sequence_length = sequence_length
        self.generator_id = generator_id
        self.normalize = normalize

        # åŠ è½½æ¨ç†æ•°æ®
        print(f"åŠ è½½æ¨ç†æ•°æ®é›†: {data_file}")
        with open(data_file, 'r') as f:
            self.data = json.load(f)

        # æ£€æŸ¥æ•°æ®æ ¼å¼å¹¶è·å–æ•°æ®
        self.values, self.labels = self._load_data()

        # æ•°æ®é¢„å¤„ç†
        if normalize:
            self.values = self._normalize_data(self.values)

        # åˆ›å»ºåºåˆ—
        self.samples, self.sample_labels = self._create_sequences()

        print(f"æ•°æ®åŠ è½½å®Œæˆ: {len(self.samples)} ä¸ªæ ·æœ¬")
        print(f"æ­£æ ·æœ¬æ¯”ä¾‹: {np.mean(self.sample_labels):.3f}")

    def _load_data(self):
        """åŠ è½½æ•°æ®ï¼ˆé€‚é…åŸå§‹æ•°æ®ç”Ÿæˆå™¨æ ¼å¼ï¼‰"""
        # å°è¯•åŸå§‹æ•°æ®ç”Ÿæˆå™¨æ ¼å¼
        values_key = f"time_sequence_{self.generator_id}_value"
        labels_key = f"time_sequence_{self.generator_id}_label"

        if values_key in self.data and labels_key in self.data:
            print(f"ä½¿ç”¨æ•°æ®ç”Ÿæˆå™¨æ ¼å¼: {values_key}, {labels_key}")
            values = np.array(self.data[values_key], dtype=np.float32)
            labels = np.array(self.data[labels_key], dtype=np.float32)
        # å°è¯•ç®€å•æ ¼å¼ï¼ˆå…¼å®¹æ—§ç‰ˆæœ¬ï¼‰
        elif 'values' in self.data and 'labels' in self.data:
            print("ä½¿ç”¨ç®€å•æ ¼å¼: values, labels")
            values = np.array(self.data['values'], dtype=np.float32)
            labels = np.array(self.data['labels'], dtype=np.float32)
        else:
            # å°è¯•è‡ªåŠ¨æ£€æµ‹æ ¼å¼
            available_keys = list(self.data.keys())
            print(f"å¯ç”¨æ•°æ®é”®: {available_keys}")

            # å°è¯•è‡ªåŠ¨æ£€æµ‹æ ¼å¼
            value_keys = [k for k in available_keys if 'value' in k.lower()]
            label_keys = [k for k in available_keys if 'label' in k.lower()]

            if value_keys and label_keys:
                print(f"è‡ªåŠ¨æ£€æµ‹åˆ°å€¼é”®: {value_keys[0]}, æ ‡ç­¾é”®: {label_keys[0]}")
                values = np.array(self.data[value_keys[0]], dtype=np.float32)
                labels = np.array(self.data[label_keys[0]], dtype=np.float32)
            else:
                raise ValueError(
                    f"æ•°æ®æ ¼å¼é”™è¯¯: æ— æ³•è¯†åˆ«æ•°æ®æ ¼å¼ã€‚æœŸæœ›çš„æ•°æ®ç”Ÿæˆå™¨æ ¼å¼åŒ…å« '{values_key}' å’Œ '{labels_key}' é”®")

        if len(values) != len(labels):
            raise ValueError(f"æ•°æ®é•¿åº¦ä¸åŒ¹é…: values({len(values)}) != labels({len(labels)})")

        print(f"æ•°æ®ç»´åº¦: values={values.shape}, labels={labels.shape}")
        return values, labels

    def _normalize_data(self, values):
        """æ ‡å‡†åŒ–æ•°æ®"""
        mean = np.mean(values)
        std = np.std(values)
        normalized = (values - mean) / std
        print(f"æ•°æ®æ ‡å‡†åŒ–: mean={mean:.4f}, std={std:.4f}")
        return normalized

    def _create_sequences(self):
        """åˆ›å»ºåºåˆ—"""
        sequences = []
        sequence_labels = []

        # æ£€æŸ¥æ•°æ®é•¿åº¦æ˜¯å¦è¶³å¤Ÿ
        if len(self.values) < self.sequence_length:
            raise ValueError(f"æ•°æ®é•¿åº¦({len(self.values)})å°äºåºåˆ—é•¿åº¦({self.sequence_length})")

        # åˆ›å»ºæ»‘åŠ¨çª—å£
        for i in range(len(self.values) - self.sequence_length + 1):
            seq = self.values[i:i + self.sequence_length]
            label = self.labels[i + self.sequence_length - 1]

            sequences.append(seq)
            sequence_labels.append(label)

        return np.array(sequences, dtype=np.float32), np.array(sequence_labels, dtype=np.float32)

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        sample = self.samples[idx]
        label = self.sample_labels[idx]

        # è½¬æ¢ä¸ºPyTorchå¼ é‡ï¼Œæ·»åŠ ç‰¹å¾ç»´åº¦
        sample_tensor = torch.FloatTensor(sample).unsqueeze(-1)  # å½¢çŠ¶: [sequence_length, 1]
        label_tensor = torch.FloatTensor([label])

        return sample_tensor, label_tensor


class QuantizedModelAnalyzer:
    """é‡åŒ–æ¨¡å‹æ¨ç†åˆ†æå™¨"""

    def __init__(self, model_path, device='cpu'):
        self.device = torch.device(device)
        self.model_path = model_path
        self.model = None
        self.config = None
        self.results = {}

        # åŠ è½½æ¨¡å‹
        self._load_model()

    def _load_model(self):
        """åŠ è½½é‡åŒ–æ¨¡å‹ - ä¿®å¤ç‰ˆæœ¬"""
        try:
            print(f"åŠ è½½é‡åŒ–æ¨¡å‹: {self.model_path}")
            checkpoint = torch.load(self.model_path, map_location=self.device)

            # è·å–æ¨¡å‹é…ç½®
            if 'config' in checkpoint:
                self.config = checkpoint['config']
            else:
                # é»˜è®¤é…ç½®ï¼ˆåº”ä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰
                self.config = {
                    'input_dim': 1,
                    'seq_length': 10,
                    'conv_channels': 16,
                    'lstm_hidden': 32,
                    'lstm_layers': 2,
                    'dropout_rate': 0.2
                }

            print(f"æ¨¡å‹é…ç½®: {self.config}")

            # æ£€æŸ¥æ˜¯å¦æ˜¯é‡åŒ–æ¨¡å‹
            is_quantized = checkpoint.get('quantized', False)
            hybrid_precision = checkpoint.get('hybrid_precision', False)
            
            print(f"æ¨¡å‹ç±»å‹: {'é‡åŒ–æ¨¡å‹' if is_quantized else 'æ™®é€šæ¨¡å‹'}")
            if is_quantized:
                print(f"é‡åŒ–æ¨¡å¼: {'æ··åˆç²¾åº¦(CNN-INT8 + LSTM-FP32)' if hybrid_precision else 'å…¨é‡åŒ–'}")

            # åˆ›å»ºæ··åˆç²¾åº¦æ¨¡å‹å®ä¾‹
            self.model = HybridPrecision1DCLSTM(**self.config)
            self.model.to(self.device)
            self.model.eval()

            if is_quantized:
                # å¯¹äºé‡åŒ–æ¨¡å‹ï¼Œéœ€è¦å‡†å¤‡å¹¶è½¬æ¢æ¨¡å‹
                print("å‡†å¤‡é‡åŒ–æ¨¡å‹...")
                
                # èåˆæ¨¡å—ï¼ˆä¼˜åŒ–é‡åŒ–æ€§èƒ½ï¼‰
                self.model.fuse_modules()
                
                # å‡†å¤‡é‡åŒ–ï¼ˆè®¾ç½®é‡åŒ–é…ç½®ï¼‰
                self.model.prepare_for_quantization()
                
                # è½¬æ¢ä¸ºé‡åŒ–æ¨¡å‹
                print("è½¬æ¢æ¨¡å‹ä¸ºé‡åŒ–æ ¼å¼...")
                self.model = self.model.convert_to_quantized()
                
                # åŠ è½½çŠ¶æ€å­—å…¸
                if 'model_state_dict' in checkpoint:
                    print("åŠ è½½é‡åŒ–æ¨¡å‹çŠ¶æ€å­—å…¸...")
                    # é‡åŒ–æ¨¡å‹å¯ä»¥ç›´æ¥åŠ è½½çŠ¶æ€å­—å…¸
                    self.model.load_state_dict(checkpoint['model_state_dict'])
                else:
                    print("è­¦å‘Š: æ£€æŸ¥ç‚¹ä¸­æœªæ‰¾åˆ°model_state_dict")
                    
            else:
                # å¯¹äºæ™®é€šæ¨¡å‹ï¼Œç›´æ¥åŠ è½½
                print("åŠ è½½æ™®é€šæ¨¡å‹çŠ¶æ€å­—å…¸...")
                if 'model_state_dict' in checkpoint:
                    self.model.load_state_dict(checkpoint['model_state_dict'], strict=False)
                else:
                    self.model.load_state_dict(checkpoint, strict=False)

            self.model.to(self.device)
            self.model.eval()
            print(f"æ¨¡å‹åŠ è½½æˆåŠŸï¼Œè®¾å¤‡: {self.device}")
            
            # æ˜¾ç¤ºé‡åŒ–ä¿¡æ¯
            if is_quantized:
                print("\né‡åŒ–é…ç½®ä¿¡æ¯:")
                for name, module in self.model.named_modules():
                    if hasattr(module, 'qconfig') and module.qconfig is not None:
                        quant_type = "INT8é‡åŒ–" if module.qconfig.weight.p.keywords['dtype'] == torch.qint8 else "FP32"
                        print(f"  {name}: {quant_type}")
                    elif isinstance(module, nn.LSTM):
                        print(f"  {name}: LSTMéƒ¨åˆ† (FP32ä¿ç•™)")

        except Exception as e:
            print(f"é‡åŒ–æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            raise

    def inference(self, data_loader, threshold=0.5):
        """æ‰§è¡Œæ¨ç†"""
        all_predictions = []
        all_probabilities = []
        all_labels = []
        inference_times = []

        print("å¼€å§‹é‡åŒ–æ¨¡å‹æ¨ç†...")

        with torch.no_grad():
            for batch_idx, (data, target) in enumerate(data_loader):
                data, target = data.to(self.device), target.to(self.device)

                # è®¡æ—¶æ¨ç†
                start_time = time.perf_counter()
                output = self.model(data)
                inference_time = time.perf_counter() - start_time

                probabilities = output.cpu().numpy().flatten()
                predictions = (probabilities > threshold).astype(int)

                all_probabilities.extend(probabilities)
                all_predictions.extend(predictions)
                all_labels.extend(target.cpu().numpy().flatten())
                inference_times.append(inference_time)

                if (batch_idx + 1) % 10 == 0:
                    print(f"å·²å¤„ç† {batch_idx + 1}/{len(data_loader)} æ‰¹æ¬¡")

        total_samples = len(all_labels)
        total_time = sum(inference_times)

        results = {
            'predictions': np.array(all_predictions),
            'probabilities': np.array(all_probabilities),
            'labels': np.array(all_labels),
            'inference_times': inference_times,
            'total_samples': total_samples,
            'total_time': total_time,
            'avg_time_per_sample': total_time / total_samples * 1000,  # æ¯«ç§’
            'throughput': total_samples / total_time  # æ ·æœ¬/ç§’
        }

        print(f"é‡åŒ–æ¨¡å‹æ¨ç†å®Œæˆ: {total_samples} ä¸ªæ ·æœ¬, æ€»æ—¶é—´: {total_time:.2f} ç§’")
        print(f"å¹³å‡æ¨ç†æ—¶é—´: {results['avg_time_per_sample']:.2f} ms/æ ·æœ¬")
        print(f"ååé‡: {results['throughput']:.2f} æ ·æœ¬/ç§’")

        return results

    def calculate_metrics(self, predictions, labels, probabilities):
        """è®¡ç®—è¯„ä¼°æŒ‡æ ‡"""
        # åŸºç¡€æŒ‡æ ‡
        accuracy = accuracy_score(labels, predictions)
        precision = precision_score(labels, predictions, zero_division=0)
        recall = recall_score(labels, predictions, zero_division=0)
        f1 = f1_score(labels, predictions, zero_division=0)

        # AUC
        if len(np.unique(labels)) > 1:
            try:
                auc_score = roc_auc_score(labels, probabilities)
            except:
                auc_score = 0.0
        else:
            auc_score = 0.0

        # æ··æ·†çŸ©é˜µ
        cm = confusion_matrix(labels, predictions)
        if cm.size == 4:
            tn, fp, fn, tp = cm.ravel()
        else:
            tn, fp, fn, tp = 0, 0, 0, 0

        # è¯¦ç»†æŒ‡æ ‡
        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0
        fpr = fp / (fp + tn) if (fp + tn) > 0 else 0
        fnr = fn / (fn + tp) if (fn + tp) > 0 else 0
        npv = tn / (tn + fn) if (tn + fn) > 0 else 0  # é˜´æ€§é¢„æµ‹å€¼
        prevalence = (tp + fn) / (tp + fp + tn + fn)  # æ‚£ç—…ç‡

        # F1åˆ†æ•°çš„å˜ä½“
        f2_score_value = (5 * precision * recall) / (4 * precision + recall + 1e-8) if (precision + recall) > 0 else 0

        return {
            'accuracy': accuracy,
            'precision': precision,
            'recall': recall,
            'f1_score': f1,
            'f2_score': f2_score_value,
            'auc': auc_score,
            'specificity': specificity,
            'fpr': fpr,
            'fnr': fnr,
            'npv': npv,
            'prevalence': prevalence,
            'confusion_matrix': cm.tolist(),
            'tp': int(tp), 'fp': int(fp), 'tn': int(tn), 'fn': int(fn)
        }

    def analyze_threshold(self, probabilities, labels, thresholds=None):
        """åˆ†æä¸åŒé˜ˆå€¼ä¸‹çš„æ€§èƒ½"""
        if thresholds is None:
            thresholds = np.arange(0.1, 1.0, 0.05)

        threshold_analysis = {}

        for threshold in thresholds:
            predictions = (probabilities > threshold).astype(int)
            metrics = self.calculate_metrics(predictions, labels, probabilities)
            threshold_analysis[threshold] = metrics

        return threshold_analysis

    def plot_confusion_matrix(self, cm, title="é‡åŒ–æ¨¡å‹æ··æ·†çŸ©é˜µ", save_path=None):
        """ç»˜åˆ¶æ··æ·†çŸ©é˜µ"""
        plt.figure(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                    xticklabels=['é¢„æµ‹æ­£å¸¸', 'é¢„æµ‹æ•…éšœ'],
                    yticklabels=['çœŸå®æ­£å¸¸', 'çœŸå®æ•…éšœ'])
        plt.title(title, fontsize=14)
        plt.ylabel('çœŸå®æ ‡ç­¾', fontsize=12)
        plt.xlabel('é¢„æµ‹æ ‡ç­¾', fontsize=12)
        plt.tight_layout()

        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"æ··æ·†çŸ©é˜µå·²ä¿å­˜: {save_path}")
        plt.show()

    def plot_roc_curve(self, labels, probabilities, title="é‡åŒ–æ¨¡å‹ROCæ›²çº¿", save_path=None):
        """ç»˜åˆ¶ROCæ›²çº¿"""
        if len(np.unique(labels)) > 1:
            fpr, tpr, thresholds = roc_curve(labels, probabilities)
            auc_score = roc_auc_score(labels, probabilities)

            plt.figure(figsize=(8, 6))
            plt.plot(fpr, tpr, label=f'ROCæ›²çº¿ (AUC = {auc_score:.4f})', linewidth=2)
            plt.plot([0, 1], [0, 1], 'k--', label='éšæœºåˆ†ç±»å™¨', linewidth=1, alpha=0.5)
            plt.fill_between(fpr, tpr, alpha=0.2)
            plt.xlim([0.0, 1.0])
            plt.ylim([0.0, 1.05])
            plt.xlabel('å‡æ­£ç‡ (FPR)', fontsize=12)
            plt.ylabel('çœŸæ­£ç‡ (TPR)', fontsize=12)
            plt.title(title, fontsize=14)
            plt.legend(loc='lower right')
            plt.grid(True, alpha=0.3)
            plt.tight_layout()

            if save_path:
                plt.savefig(save_path, dpi=300, bbox_inches='tight')
                print(f"ROCæ›²çº¿å·²ä¿å­˜: {save_path}")
            plt.show()

            return auc_score, fpr, tpr, thresholds
        else:
            print("è­¦å‘Š: æ•°æ®ä¸­åªæœ‰ä¸€ä¸ªç±»åˆ«ï¼Œæ— æ³•ç»˜åˆ¶ROCæ›²çº¿")
            return 0.0, None, None, None

    def plot_precision_recall_curve(self, labels, probabilities, title="é‡åŒ–æ¨¡å‹ç²¾ç¡®ç‡-å¬å›ç‡æ›²çº¿", save_path=None):
        """ç»˜åˆ¶ç²¾ç¡®ç‡-å¬å›ç‡æ›²çº¿"""
        precision, recall, thresholds = precision_recall_curve(labels, probabilities)

        plt.figure(figsize=(8, 6))
        plt.plot(recall, precision, label='P-Ræ›²çº¿', linewidth=2)
        plt.fill_between(recall, precision, alpha=0.2)
        plt.xlabel('å¬å›ç‡ (Recall)', fontsize=12)
        plt.ylabel('ç²¾ç¡®ç‡ (Precision)', fontsize=12)
        plt.title(title, fontsize=14)
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.tight_layout()

        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"P-Ræ›²çº¿å·²ä¿å­˜: {save_path}")
        plt.show()

        return precision, recall, thresholds

    def plot_threshold_analysis(self, threshold_analysis, save_path=None):
        """ç»˜åˆ¶é˜ˆå€¼åˆ†æå›¾"""
        thresholds = list(threshold_analysis.keys())
        f1_scores = [threshold_analysis[t]['f1_score'] for t in thresholds]
        precisions = [threshold_analysis[t]['precision'] for t in thresholds]
        recalls = [threshold_analysis[t]['recall'] for t in thresholds]

        plt.figure(figsize=(10, 6))
        plt.plot(thresholds, f1_scores, 'b-', label='F1åˆ†æ•°', linewidth=2)
        plt.plot(thresholds, precisions, 'r-', label='ç²¾ç¡®ç‡', linewidth=2)
        plt.plot(thresholds, recalls, 'g-', label='å¬å›ç‡', linewidth=2)
        plt.xlabel('åˆ†ç±»é˜ˆå€¼', fontsize=12)
        plt.ylabel('åˆ†æ•°', fontsize=12)
        plt.title('é‡åŒ–æ¨¡å‹é˜ˆå€¼æ•æ„Ÿæ€§åˆ†æ', fontsize=14)
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.tight_layout()

        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"é˜ˆå€¼åˆ†æå›¾å·²ä¿å­˜: {save_path}")
        plt.show()

        # æ‰¾åˆ°æœ€ä½³é˜ˆå€¼
        best_idx = np.argmax(f1_scores)
        best_threshold = thresholds[best_idx]
        best_f1 = f1_scores[best_idx]

        print(f"æœ€ä½³é˜ˆå€¼: {best_threshold:.2f} (F1åˆ†æ•°: {best_f1:.4f})")
        return best_threshold

    def plot_probability_distribution(self, probabilities, labels, title="é‡åŒ–æ¨¡å‹é¢„æµ‹æ¦‚ç‡åˆ†å¸ƒ", save_path=None):
        """ç»˜åˆ¶é¢„æµ‹æ¦‚ç‡åˆ†å¸ƒ"""
        pred_normal = probabilities[labels == 0]
        pred_fault = probabilities[labels == 1]

        plt.figure(figsize=(10, 6))

        if len(pred_normal) > 0:
            plt.hist(pred_normal, bins=20, alpha=0.7, label='æ­£å¸¸æ ·æœ¬', color='green')
        if len(pred_fault) > 0:
            plt.hist(pred_fault, bins=20, alpha=0.7, label='æ•…éšœæ ·æœ¬', color='red')

        plt.axvline(x=0.5, color='blue', linestyle='--', label='é˜ˆå€¼(0.5)')
        plt.xlabel('é¢„æµ‹æ¦‚ç‡', fontsize=12)
        plt.ylabel('æ ·æœ¬æ•°é‡', fontsize=12)
        plt.title(title, fontsize=14)
        plt.legend()
        plt.grid(True, alpha=0.3)
        plt.tight_layout()

        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"æ¦‚ç‡åˆ†å¸ƒå›¾å·²ä¿å­˜: {save_path}")
        plt.show()

    def generate_detailed_report(self, results, dataset_name="æ¨ç†æ•°æ®é›†"):
        """ç”Ÿæˆè¯¦ç»†åˆ†ææŠ¥å‘Š"""
        metrics = self.calculate_metrics(
            results['predictions'],
            results['labels'],
            results['probabilities']
        )

        print(f"\n{'=' * 80}")
        print(f"é‡åŒ–1DCNN-LSTMæ¨¡å‹æ¨ç†åˆ†ææŠ¥å‘Š - {dataset_name}")
        print(f"{'=' * 80}")

        # æ•°æ®é›†ç»Ÿè®¡
        print(f"\nğŸ“Š æ•°æ®é›†ç»Ÿè®¡:")
        print(f"  æ€»æ ·æœ¬æ•°: {results['total_samples']}")
        print(f"  æ­£æ ·æœ¬æ•°: {np.sum(results['labels'])}")
        print(f"  è´Ÿæ ·æœ¬æ•°: {len(results['labels']) - np.sum(results['labels'])}")
        print(f"  æ­£æ ·æœ¬æ¯”ä¾‹: {np.mean(results['labels']):.3f}")

        # æ€§èƒ½æŒ‡æ ‡
        print(f"\nğŸ“ˆ æ€§èƒ½æŒ‡æ ‡ (é˜ˆå€¼=0.5):")
        print(f"  å‡†ç¡®ç‡ (Accuracy): {metrics['accuracy']:.4f}")
        print(f"  ç²¾ç¡®ç‡ (Precision): {metrics['precision']:.4f}")
        print(f"  å¬å›ç‡ (Recall): {metrics['recall']:.4f}")
        print(f"  F1åˆ†æ•°: {metrics['f1_score']:.4f}")
        print(f"  F2åˆ†æ•°: {metrics['f2_score']:.4f}")
        print(f"  AUC: {metrics['auc']:.4f}")
        print(f"  ç‰¹å¼‚åº¦ (Specificity): {metrics['specificity']:.4f}")
        print(f"  é˜´æ€§é¢„æµ‹å€¼ (NPV): {metrics['npv']:.4f}")

        # é”™è¯¯ç‡
        print(f"\nâš ï¸  é”™è¯¯åˆ†æ:")
        print(f"  å‡æ­£ç‡ (FPR): {metrics['fpr']:.4f}")
        print(f"  å‡è´Ÿç‡ (FNR): {metrics['fnr']:.4f}")

        # æ¨ç†æ€§èƒ½
        print(f"\nâš¡ æ¨ç†æ€§èƒ½:")
        print(f"  æ€»æ¨ç†æ—¶é—´: {results['total_time']:.2f} ç§’")
        print(f"  å¹³å‡æ¨ç†æ—¶é—´: {results['avg_time_per_sample']:.2f} æ¯«ç§’/æ ·æœ¬")
        print(f"  ååé‡: {results['throughput']:.2f} æ ·æœ¬/ç§’")

        # æ¨¡å‹ä¿¡æ¯
        print(f"\nğŸ¤– æ¨¡å‹ä¿¡æ¯:")
        print(f"  æ¨¡å‹ç±»å‹: é‡åŒ–1DCNN-LSTM (CNN-INT8 + LSTM-FP32)")
        print(f"  æ¨¡å‹è·¯å¾„: {self.model_path}")

        # æ··æ·†çŸ©é˜µ
        print(f"\nğŸ“Š æ··æ·†çŸ©é˜µ:")
        cm = np.array(metrics['confusion_matrix'])
        print(f"         é¢„æµ‹æ­£å¸¸  é¢„æµ‹æ•…éšœ")
        print(f"çœŸå®æ­£å¸¸   {cm[0][0]:6d}    {cm[0][1]:6d}")
        print(f"çœŸå®æ•…éšœ   {cm[1][0]:6d}    {cm[1][1]:6d}")

        # è¯¦ç»†åˆ†ç±»æŠ¥å‘Š
        print(f"\nğŸ“‹ è¯¦ç»†åˆ†ç±»æŠ¥å‘Š:")
        print(classification_report(results['labels'], results['predictions'],
                                    target_names=['æ­£å¸¸', 'æ•…éšœ'], digits=4))

        # ä¿å­˜ç»“æœ
        report_data = {
            'dataset_name': dataset_name,
            'timestamp': time.strftime("%Y-%m-%d %H:%M:%S"),
            'model_path': self.model_path,
            'model_config': self.config,
            'model_type': 'quantized_1dclstm',
            'dataset_statistics': {
                'total_samples': int(results['total_samples']),
                'positive_samples': int(np.sum(results['labels'])),
                'negative_samples': int(len(results['labels']) - np.sum(results['labels'])),
                'positive_ratio': float(np.mean(results['labels']))
            },
            'performance_metrics': metrics,
            'inference_performance': {
                'total_time': float(results['total_time']),
                'avg_time_per_sample': float(results['avg_time_per_sample']),
                'throughput': float(results['throughput'])
            },
            'predictions': results['predictions'].tolist(),
            'probabilities': results['probabilities'].tolist(),
            'labels': results['labels'].tolist()
        }

        return report_data, metrics

    def run_analysis(self, data_file, batch_size=64, threshold=0.5,
                     save_plots=True, output_dir='quantized_results', generator_id=1):
        """è¿è¡Œå®Œæ•´åˆ†ææµç¨‹"""

        # åˆ›å»ºè¾“å‡ºç›®å½•
        if save_plots and not os.path.exists(output_dir):
            os.makedirs(output_dir)

        # åŠ è½½æ¨ç†æ•°æ®é›†
        dataset = InferenceDataset(data_file,
                                   sequence_length=self.config['seq_length'],
                                   generator_id=generator_id)
        data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)

        print(f"\n{'=' * 80}")
        print("å¼€å§‹é‡åŒ–æ¨¡å‹æ¨ç†æµ‹è¯•åˆ†æ")
        print(f"æ•°æ®é›†: {data_file}")
        print(f"æ‰¹æ¬¡å¤§å°: {batch_size}")
        print(f"åˆ†ç±»é˜ˆå€¼: {threshold}")
        print(f"å‘ç”Ÿå™¨ID: {generator_id}")
        print(f"{'=' * 80}")

        # æ‰§è¡Œæ¨ç†
        results = self.inference(data_loader, threshold=threshold)

        # ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
        report_data, metrics = self.generate_detailed_report(results, "é‡åŒ–æ¨¡å‹æ¨ç†æµ‹è¯•é›†")

        # å¯è§†åŒ–åˆ†æ
        if save_plots:
            print(f"\nğŸ“Š ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")

            # æ··æ·†çŸ©é˜µ
            cm = np.array(metrics['confusion_matrix'])
            self.plot_confusion_matrix(
                cm,
                title="é‡åŒ–1DCNN-LSTMæ¨¡å‹æ··æ·†çŸ©é˜µ",
                save_path=os.path.join(output_dir, 'quantized_confusion_matrix.png')
            )

            # ROCæ›²çº¿
            if len(np.unique(results['labels'])) > 1:
                self.plot_roc_curve(
                    results['labels'], results['probabilities'],
                    title="é‡åŒ–1DCNN-LSTMæ¨¡å‹ROCæ›²çº¿",
                    save_path=os.path.join(output_dir, 'quantized_roc_curve.png')
                )

            # ç²¾ç¡®ç‡-å¬å›ç‡æ›²çº¿
            self.plot_precision_recall_curve(
                results['labels'], results['probabilities'],
                title="é‡åŒ–1DCNN-LSTMæ¨¡å‹ç²¾ç¡®ç‡-å¬å›ç‡æ›²çº¿",
                save_path=os.path.join(output_dir, 'quantized_pr_curve.png')
            )

            # æ¦‚ç‡åˆ†å¸ƒ
            self.plot_probability_distribution(
                results['probabilities'], results['labels'],
                title="é‡åŒ–1DCNN-LSTMæ¨¡å‹é¢„æµ‹æ¦‚ç‡åˆ†å¸ƒ",
                save_path=os.path.join(output_dir, 'quantized_probability_distribution.png')
            )

            # é˜ˆå€¼åˆ†æ
            threshold_analysis = self.analyze_threshold(
                results['probabilities'], results['labels']
            )
            best_threshold = self.plot_threshold_analysis(
                threshold_analysis,
                save_path=os.path.join(output_dir, 'quantized_threshold_analysis.png')
            )

            report_data['optimal_threshold'] = float(best_threshold)
            report_data['generator_id'] = generator_id

        # ä¿å­˜æŠ¥å‘Š
        report_file = os.path.join(output_dir, 'quantized_inference_report.json')
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, indent=2, ensure_ascii=False)

        print(f"\nâœ… é‡åŒ–æ¨¡å‹åˆ†æå®Œæˆ!")
        print(f"æŠ¥å‘Šå·²ä¿å­˜: {report_file}")

        if save_plots:
            print(f"å›¾è¡¨å·²ä¿å­˜åˆ°: {output_dir}/")

        return report_data, results


def main():
    """ä¸»å‡½æ•° - æ‰§è¡Œé‡åŒ–æ¨¡å‹æ¨ç†åˆ†æ"""

    # é…ç½®å‚æ•°
    QUANTIZED_MODEL_PATH = "hybrid_precision_model.pth"  # é‡åŒ–æ¨¡å‹è·¯å¾„
    INFERENCE_DATA_FILE = "dataset.json"  # æ¨ç†æ•°æ®é›†è·¯å¾„
    BATCH_SIZE = 64  # æ‰¹æ¬¡å¤§å°
    THRESHOLD = 0.5  # åˆ†ç±»é˜ˆå€¼
    GENERATOR_ID = 1  # å‘ç”Ÿå™¨ID
    SAVE_PLOTS = True  # æ˜¯å¦ä¿å­˜å›¾è¡¨
    OUTPUT_DIR = "quantized_inference_results"  # è¾“å‡ºç›®å½•

    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(QUANTIZED_MODEL_PATH):
        print(f"âŒ é”™è¯¯: é‡åŒ–æ¨¡å‹æ–‡ä»¶ {QUANTIZED_MODEL_PATH} ä¸å­˜åœ¨")
        print("è¯·å…ˆè¿è¡Œé‡åŒ–è„šæœ¬ç”Ÿæˆé‡åŒ–æ¨¡å‹")
        print("è¿è¡Œå‘½ä»¤: python ann_quantization.py")
        return

    if not os.path.exists(INFERENCE_DATA_FILE):
        print(f"âŒ é”™è¯¯: æ¨ç†æ•°æ®æ–‡ä»¶ {INFERENCE_DATA_FILE} ä¸å­˜åœ¨")
        print("è¯·æ£€æŸ¥æ•°æ®æ–‡ä»¶è·¯å¾„")
        return

    try:
        # åˆå§‹åŒ–é‡åŒ–æ¨¡å‹åˆ†æå™¨
        analyzer = QuantizedModelAnalyzer(QUANTIZED_MODEL_PATH)

        # è¿è¡Œå®Œæ•´åˆ†æ
        report, results = analyzer.run_analysis(
            data_file=INFERENCE_DATA_FILE,
            batch_size=BATCH_SIZE,
            threshold=THRESHOLD,
            save_plots=SAVE_PLOTS,
            output_dir=OUTPUT_DIR,
            generator_id=GENERATOR_ID
        )

        # é˜ˆå€¼åˆ†æ
        threshold_analysis = analyzer.analyze_threshold(
            results['probabilities'], results['labels']
        )

        # æ‰¾åˆ°æœ€ä½³é˜ˆå€¼
        thresholds = list(threshold_analysis.keys())
        f1_scores = [threshold_analysis[t]['f1_score'] for t in thresholds]
        best_idx = np.argmax(f1_scores)
        best_threshold = thresholds[best_idx]
        best_f1 = f1_scores[best_idx]

        print(f"\nğŸ’¡ é‡åŒ–æ¨¡å‹æœ€ä½³é˜ˆå€¼å»ºè®®:")
        print(f"  åŸºäºF1åˆ†æ•°çš„æœ€ä½³é˜ˆå€¼: {best_threshold:.3f}")
        print(f"  å¯¹åº”çš„F1åˆ†æ•°: {best_f1:.4f}")

        # ä½¿ç”¨æœ€ä½³é˜ˆå€¼é‡æ–°è¯„ä¼°
        if best_threshold != THRESHOLD:
            print(f"\nä½¿ç”¨æœ€ä½³é˜ˆå€¼ {best_threshold:.3f} é‡æ–°è¯„ä¼°:")
            predictions_best = (results['probabilities'] > best_threshold).astype(int)
            metrics_best = analyzer.calculate_metrics(
                predictions_best, results['labels'], results['probabilities']
            )
            print(
                f"  F1åˆ†æ•°: {metrics_best['f1_score']:.4f} (åŸå§‹é˜ˆå€¼0.5: {report['performance_metrics']['f1_score']:.4f})")
            print(
                f"  ç²¾ç¡®ç‡: {metrics_best['precision']:.4f} (åŸå§‹é˜ˆå€¼0.5: {report['performance_metrics']['precision']:.4f})")
            print(
                f"  å¬å›ç‡: {metrics_best['recall']:.4f} (åŸå§‹é˜ˆå€¼0.5: {report['performance_metrics']['recall']:.4f})")

        # æ¨¡å‹å¤§å°æ¯”è¾ƒ
        print(f"\nğŸ“ æ¨¡å‹å¤§å°åˆ†æ:")
        if os.path.exists("edge_1dclstm_best.pth"):
            original_size = os.path.getsize("edge_1dclstm_best.pth") / (1024 * 1024)  # MB
            quantized_size = os.path.getsize(QUANTIZED_MODEL_PATH) / (1024 * 1024)  # MB
            size_reduction = (original_size - quantized_size) / original_size * 100

            print(f"  åŸå§‹æ¨¡å‹å¤§å°: {original_size:.2f} MB")
            print(f"  é‡åŒ–æ¨¡å‹å¤§å°: {quantized_size:.2f} MB")
            print(f"  æ¨¡å‹å‹ç¼©ç‡: {size_reduction:.1f}%")
        else:
            print("  åŸå§‹æ¨¡å‹æ–‡ä»¶æœªæ‰¾åˆ°ï¼Œè·³è¿‡æ¨¡å‹å¤§å°æ¯”è¾ƒ")

    except Exception as e:
        print(f"âŒ é‡åŒ–æ¨¡å‹åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    # è®¾ç½®matplotlibå­—ä½“
    try:
        # è®¾ç½®ä¸­æ–‡å­—ä½“
        plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False
    except:
        print("è­¦å‘Š: å­—ä½“è®¾ç½®å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å­—ä½“")

    print("\n" + "=" * 80)
    print("é‡åŒ–1DCNN-LSTMæ¨¡å‹æ¨ç†åˆ†æ")
    print("=" * 80)

    # è¿è¡Œä¸»å‡½æ•°
    main()
